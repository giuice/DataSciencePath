{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Basics Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by reading the data into pandas. Let's look at what happens when we use the pandas.read_csv() function with only the filename argument:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an error! (The error message has been shortened.) This error references UTF-8, which is a type of encoding. Computers, at their lowest levels, can only understand binary - 0 and 1- and encodings are systems for representing characters in binary.\n",
    "\n",
    "Something we can do if our file has an unknown encoding is to try the most common encodings:\n",
    "\n",
    "* UTF-8\n",
    "* Latin-1 (also known as ISO-8895-1)\n",
    "* Windows-1251"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the pandas library\n",
    "1. Use the pandas.read_csv() function to read the laptops.csv file into a dataframe laptops.\n",
    "2. Specify the encoding using the string \"Latin-1\".\n",
    "3. Use the DataFrame.info() method to display information about the laptops dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1303 entries, 0 to 1302\n",
      "Data columns (total 13 columns):\n",
      "Manufacturer                1303 non-null object\n",
      "Model Name                  1303 non-null object\n",
      "Category                    1303 non-null object\n",
      "Screen Size                 1303 non-null object\n",
      "Screen                      1303 non-null object\n",
      "CPU                         1303 non-null object\n",
      "RAM                         1303 non-null object\n",
      " Storage                    1303 non-null object\n",
      "GPU                         1303 non-null object\n",
      "Operating System            1303 non-null object\n",
      "Operating System Version    1133 non-null object\n",
      "Weight                      1303 non-null object\n",
      "Price (Euros)               1303 non-null object\n",
      "dtypes: object(13)\n",
      "memory usage: 132.5+ KB\n"
     ]
    }
   ],
   "source": [
    "laptops = pd.read_csv('laptops.csv', encoding='Latin-1')\n",
    "laptops.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that every column is represented as the object type, indicating that they are represented by strings, not numbers. Also, one of the columns, Operating System Version, has null values.\n",
    "\n",
    "The column labels have a variety of upper and lowercase letters, as well as spaces and parentheses, which will make them harder to work with and read. One noticeable issue is that the \" Storage\" column name has a space in front of it. These quirks with column labels can sometimes be hard to spot, so removing extra whitespaces from all column names will save us more work in the long run.\n",
    "\n",
    "We can access the column axis of a dataframe using the DataFrame.columns attribute. This returns an index object — a special type of NumPy ndarray — with the labels of each column:\n",
    "```python\n",
    "print(laptops.columns)\n",
    "Index(['Manufacturer', 'Model Name', 'Category', 'Screen Size', 'Screen',\n",
    "       'CPU', 'RAM', ' Storage', 'GPU', 'Operating System',\n",
    "       'Operating System Version', 'Weight', 'Price (Euros)'],\n",
    "      dtype='object')\n",
    "```\n",
    "Not only can we use the attribute to view the column labels, we can also assign new labels to the attribute:\n",
    "```python\n",
    "laptops_test = laptops.copy()\n",
    "laptops_test.columns = ['A', 'B', 'C', 'D', 'E',\n",
    "                        'F', 'G', 'H', 'I', 'J',\n",
    "                        'K', 'L', 'M']\n",
    "print(laptops_test.columns)\n",
    "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M'], dtype='object')\n",
    "```\n",
    "Next, let's use the DataFrame.columns attribute to remove whitespaces from the column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove any whitespace from the start and end of each column name.\n",
    "    - Create an empty list named new_columns.\n",
    "    - Use a for loop to iterate through each column name using the DataFrame.columns attribute. Inside the body of the for loop:\n",
    "        <br> Use the str.strip() method to remove whitespace from the start and end of the string.\n",
    "        <br> Append the updated column name to the new_columns list.\n",
    "    - Assign the updated column names to the DataFrame.columns attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = []\n",
    "for column in laptops.columns:\n",
    "    new_columns.append(str.strip(column))\n",
    "laptops.columns = new_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last exercise, we removed whitespaces from the column names. Below is the result:\n",
    "```python\n",
    "Index(['Manufacturer', 'Model Name', 'Category', 'Screen Size', 'Screen',\n",
    "       'CPU', 'RAM', 'Storage', 'GPU', 'Operating System',\n",
    "       'Operating System Version', 'Weight', 'Price (Euros)'],\n",
    "      dtype='object')\n",
    "```\n",
    "However, the column labels still have a variety of upper and lowercase letters, as well as parentheses, which will make them harder to work with and read. Let's finish cleaning our column labels by:\n",
    "\n",
    "Replacing spaces with underscores.\n",
    "Removing special characters.\n",
    "Making all labels lowercase.\n",
    "Shortening any long column names.\n",
    "We can create a function that uses Python string methods to clean our column labels, and then again use a loop to apply that function to each label. Let's look at an example:\n",
    "```python\n",
    "def clean_col(col):\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"(\",\"\")\n",
    "    col = col.replace(\")\",\"\")\n",
    "    col = col.lower()\n",
    "    return col\n",
    "​\n",
    "new_columns = []\n",
    "for c in laptops.columns:\n",
    "    clean_c = clean_col(c)\n",
    "    new_columns.append(clean_c)\n",
    "Index(['manufacturer', 'model name', 'category', 'screen size', 'screen',\n",
    "       'cpu', 'ram', 'storage', 'gpu', 'operating system',\n",
    "       'operating system version', 'weight', 'price euros'],\n",
    "      dtype='object')\n",
    "```\n",
    "Our code:\n",
    "\n",
    "Defined a function, which:\n",
    "Used the str.strip() method to remove whitespace from the start and end of the string.\n",
    "Used the str.replace() method to remove parentheses from the string.\n",
    "Used the str.lower() method to make the string lowercase.\n",
    "Returns the modified string.\n",
    "Used a loop to apply the function to each item in the index object and assign it back to the DataFrame.columns attribute.\n",
    "Printed the new values for the DataFrame.columns attribute.\n",
    "Let's use this technique to clean the column labels in our dataframe, adding a few extra cleaning 'chores' along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Column labels still have a variety of upper and lowercase letters, as well as parentheses, which will make them harder to work with and read. Let's finish cleaning our column labels by:\n",
    "\n",
    "- Replacing spaces with underscores.\n",
    "- Removing special characters.\n",
    "- Making all labels lowercase.\n",
    "- Shortening any long column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['manufacturer', 'model_name', 'category', 'screen_size', 'screen',\n",
      "       'cpu', 'ram', 'storage', 'gpu', 'os', 'os_version', 'weight',\n",
      "       'price_euros'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def clean_label(label):\n",
    "    label = label.strip()\n",
    "    label = label.replace('(','').replace(')','').replace('Operating System','os').replace(' ','_')\n",
    "    label = label.lower()\n",
    "    return label\n",
    "new_columns = []\n",
    "for item in laptops.columns:\n",
    "    clean_c = clean_label(item)\n",
    "    new_columns.append(clean_c)\n",
    "\n",
    "laptops.columns = new_columns\n",
    "print(laptops.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the Series.unique() method to identify the unique values in the ram column of the laptops dataframe. \n",
    "- Assign the result to unique_ram.\n",
    "- After running your code, use the variable inspector to view the unique values in the ram column and identify any patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['8GB', '16GB', '4GB', '2GB', '12GB', '6GB', '32GB', '24GB', '64GB'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_ram = laptops['ram'].unique()\n",
    "unique_ram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas library contains dozens of vectorized string methods we can use to manipulate text data, many of which perform the same operations as Python string methods. Most vectorized string methods are available using the Series.str accessor, which means we can access them by adding str between the series name and the method name:\n",
    "![title](cleaning_workflow.svg)\n",
    "vectorized_string_methods\n",
    "In this case, we can use the Series.str.replace() method, which is a vectorized version of the Python str.replace() method we used in the previous screen, to remove all the quote characters from every string in the screen_size column:\n",
    "```python\n",
    "laptops[\"screen_size\"] = laptops[\"screen_size\"].str.replace('\"','')\n",
    "print(laptops[\"screen_size\"].unique())\n",
    "['13.3', '15.6', '15.4', '14.0', '12.0', '11.6', '17.3',\n",
    " '10.1', '13.5', '12.5', '13.0', '18.4', '13.9', '12.3',\n",
    " '17.0', '15.0', '14.1', '11.3']\n",
    "```\n",
    "Let's remove the non-digit characters from the ram column next.\n",
    "\n",
    "Instructions\n",
    "\n",
    "- Use the Series.str.replace() method to remove the substring GB from the ram column.\n",
    "- Use the Series.unique() method to assign the unique values in the ram column to unique_ram.\n",
    "- After running your code, use the variable inspector to verify your changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops.ram = laptops.ram.str.replace('GB', '')\n",
    "unique_ram = laptops.ram.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last screen, we used the Series.str.replace() method to remove the non-digit characters from the screen_size and ram columns. Now, we can convert (or cast) the columns to a numeric dtype.\n",
    "\n",
    "string to numeric cleaning workflow\n",
    "\n",
    "To do this, we use the Series.astype() method. To convert the column to a numeric dtype, we can use either int or float as the parameter for the method. Since the int dtype can't store decimal values, we'll convert the screen_size column to the float dtype:\n",
    "```python\n",
    "laptops[\"screen_size\"] = laptops[\"screen_size\"].astype(float)\n",
    "print(laptops[\"screen_size\"].dtype)\n",
    "print(laptops[\"screen_size\"].unique())\n",
    "float64\n",
    "​\n",
    "[13.3, 15.6, 15.4, 14. , 12. , 11.6, 17.3, 10.1, 13.5, 12.5,\n",
    " 13. , 18.4, 13.9, 12.3, 17. , 15. , 14.1, 11.3]\n",
    "```\n",
    "Our screen_size column is now the float64 dtype. Let's convert the dtype of the ram column to numeric next.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Use the Series.astype() method to change the ram column to an integer dtype.\n",
    "- Use the DataFrame.dtypes attribute to get a list of the column names and types from the laptops dataframe. Assign the result to dtypes.\n",
    "- After running your code, use the variable inspector to view the dtypes variable to see the results of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops[\"ram\"] = laptops[\"ram\"].str.replace('GB','')\n",
    "laptops[\"ram\"] = laptops.ram.astype(int)\n",
    "dtypes = laptops.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've converted our columns to numeric dtypes, the final step is to rename the column. This is an optional step, and can be useful if the non-digit values contain information that helps us understand the data.\n",
    "\n",
    "string to numeric cleaning workflow\n",
    "\n",
    "In our case, the quote characters we removed from the screen_size column denoted that the screen size was in inches. As a reminder, here's what the original values looked like:\n",
    "\n",
    "['13.3\"', '15.6\"', '15.4\"', '14.0\"', '12.0\"', '11.6\"',\n",
    " '17.3\"', '10.1\"', '13.5\"', '12.5\"', '13.0\"', '18.4\"',\n",
    " '13.9\"', '12.3\"', '17.0\"', '15.0\"', '14.1\"',\n",
    " '11.3\"']\n",
    "To stop us from losing information the helps us understand the data, we can use the DataFrame.rename() method to rename the column from screen_size to screen_size_inches.\n",
    "\n",
    "Below, we specify the axis=1 parameter so pandas knows that we want to rename labels in the column axis:\n",
    "```python\n",
    "laptops.rename({\"screen_size\": \"screen_size_inches\"}, axis=1, inplace=True)\n",
    "print(laptops.dtypes)\n",
    "manufacturer           object\n",
    "model_name             object\n",
    "category               object\n",
    "screen_size_inches    float64\n",
    "screen                 object\n",
    "cpu                    object\n",
    "ram                    object\n",
    "storage                object\n",
    "gpu                    object\n",
    "os                     object\n",
    "os_version             object\n",
    "weight                 object\n",
    "price_euros            object\n",
    "dtype: object\n",
    "```\n",
    "Note that we can either use inplace=True or assign the result back to the dataframe - both will give us the same results.\n",
    "\n",
    "Let's rename the ram column next and analyze the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "- Because the GB characters contained useful information about the units (gigabytes) of the laptop's ram, use the DataFrame.rename() method to rename the column from ram to ram_gb.\n",
    "- Use the Series.describe() method to return a series of descriptive statistics for the ram_gb column. Assign the result to ram_gb_desc.\n",
    "- After you have run your code, use the variable inspector to see the results of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1303.000000\n",
       "mean        8.382195\n",
       "std         5.084665\n",
       "min         2.000000\n",
       "25%         4.000000\n",
       "50%         8.000000\n",
       "75%         8.000000\n",
       "max        64.000000\n",
       "Name: ram, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops.ram.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1303.000000\n",
       "mean        8.382195\n",
       "std         5.084665\n",
       "min         2.000000\n",
       "25%         4.000000\n",
       "50%         8.000000\n",
       "75%         8.000000\n",
       "max        64.000000\n",
       "Name: ram_gb, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "laptops.rename({'ram':'ram_gb'}, axis=1, inplace=True)\n",
    "ram_gb_desc = laptops.ram_gb.describe()\n",
    "ram_gb_desc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, it can be useful to extract non-numeric values from within strings. Let's look at the first five values from the gpu (graphics processing unit) column:\n",
    "```python\n",
    "print(laptops[\"gpu\"].head())\n",
    "0    Intel Iris Plus Graphics 640\n",
    "1          Intel HD Graphics 6000\n",
    "2           Intel HD Graphics 620\n",
    "3              AMD Radeon Pro 455\n",
    "4    Intel Iris Plus Graphics 650\n",
    "\n",
    "Name: gpu, dtype: object\n",
    "```\n",
    "The information in this column seems to be a manufacturer (Intel, AMD) followed by a model name/number. Let's extract the manufacturer by itself so we can find the most common ones.\n",
    "\n",
    "Because each manufacturer is followed by a whitespace character, we can use the Series.str.split() method to extract this data:\n",
    "\n",
    "extracting data from a string, step 2\n",
    "\n",
    "This method splits each string on the whitespace; the result is a series containing individual Python lists. Also note that we used parentheses to method chain over multiple lines, which makes our code easier to read.\n",
    "\n",
    "Just like with lists and ndarrays, we can use bracket notation to access the elements in each list in the series. With series, however, we use the str accessor followed by [] (brackets):\n",
    "```python\n",
    "print(laptops[\"gpu\"].head().str.split().str[0])\n",
    "\n",
    "Above, we used 0 to select the first element in each list. Below is the result:\n",
    "\n",
    "0    Intel\n",
    "1    Intel\n",
    "2    Intel\n",
    "3      AMD\n",
    "4    Intel\n",
    "Name: gpu, dtype: object\n",
    "```\n",
    "Let's use this technique to extract the manufacturer from the cpu column as well. Here are the first 5 rows of the cpu column:\n",
    "```python\n",
    "print(laptops[\"cpu\"].head())\n",
    "\n",
    "0          Intel Core i5 2.3GHz\n",
    "1          Intel Core i5 1.8GHz\n",
    "2    Intel Core i5 7200U 2.5GHz\n",
    "3          Intel Core i7 2.7GHz\n",
    "4          Intel Core i5 3.1GHz\n",
    "Name: cpu, dtype: object\n",
    "```\n",
    "### Instructions\n",
    "\n",
    "In the example code, we have extracted the manufacturer name from the gpu column, and assigned it to a new column gpu_manufacturer.\n",
    "\n",
    "- Extract the manufacturer name from the cpu column. Assign it to a new column cpu_manufacturer.\n",
    "- Use the Series.value_counts() method to find the counts of each manufacturer in cpu_manufacturer. Assign the result to cpu_manufacturer_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intel      1240\n",
       "AMD          62\n",
       "Samsung       1\n",
       "Name: gpu_manufacturer, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops[\"gpu_manufacturer\"] = laptops.cpu.str.split().str[0]\n",
    "cpu_manufacturer_counts = laptops[\"gpu_manufacturer\"].value_counts()\n",
    "cpu_manufacturer_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your data has been scraped from a webpage or if there was manual data entry involved at some point, you may end up with inconsistent values. Let's look at an example from our os column:\n",
    "```python\n",
    "print(laptops[\"os\"].value_counts())\n",
    "Windows      1125\n",
    "No OS          66\n",
    "Linux          62\n",
    "Chrome OS      27\n",
    "macOS          13\n",
    "Mac OS          8\n",
    "Android         2\n",
    "Name: os, dtype: int64\n",
    "```\n",
    "We can see that there are two variations of the Apple operating system — macOS — in our data set: Mac OS and macOS. One way we can fix this is with the Series.map() method. The Series.map() method is ideal when we want to change multiple values in a column, but we'll use it now as an opportunity to learn how the method works.\n",
    "\n",
    "The most common way to use Series.map() is with a dictionary. Let's look at an example using a series of misspelled fruit:\n",
    "```python\n",
    "print(s)\n",
    "0       pair\n",
    "1     oranje\n",
    "2    bananna\n",
    "3     oranje\n",
    "4     oranje\n",
    "5     oranje\n",
    "dtype: object\n",
    "We'll create a dictionary called corrections and pass that dictionary as an argument to Series.map():\n",
    "\n",
    "corrections = {\n",
    "    \"pair\": \"pear\",\n",
    "    \"oranje\": \"orange\",\n",
    "    \"bananna\": \"banana\"\n",
    "}\n",
    "s = s.map(corrections)\n",
    "print(s)\n",
    "0       pear\n",
    "1     orange\n",
    "2     banana\n",
    "3     orange\n",
    "4     orange\n",
    "5     orange\n",
    "dtype: object\n",
    "```\n",
    "We can see that each of our corrections were made across our series. One important thing to remember with Series.map() is that if a value from your series doesn't exist as a key in your dictionary, it will convert that value to NaN. Let's see what happens when we run map one more time:\n",
    "```python\n",
    "s = s.map(corrections)\n",
    "print(s)\n",
    "0    NaN\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "5    NaN\n",
    "dtype: object\n",
    "```\n",
    "Because none of the corrected values in our series existed as keys in our dictionary, all values became NaN! It's a very common occurence, especially when working in Jupyter notebook, where you can easily re-run cells.\n",
    "\n",
    "Let's use Series.map() to clean the values in the os column.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "We have created a dictionary for you to use with mapping. Note that we have included both the correct and incorrect spelling of macOS as keys, otherwise we'll end up with null values.\n",
    "\n",
    "- Use the Series.map() method with the mapping_dict dictionary to correct the values in the os column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "    'Android': 'Android',\n",
    "    'Chrome OS': 'Chrome OS',\n",
    "    'Linux': 'Linux',\n",
    "    'Mac OS': 'macOS',\n",
    "    'No OS': 'No OS',\n",
    "    'Windows': 'Windows',\n",
    "    'macOS': 'macOS'\n",
    "}\n",
    "laptops.os = laptops.os.map(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------\n",
    "In previous missions, we've talked briefly about missing values and how both NumPy and pandas represent these as null values. In pandas, null values will be indicated by either NaN or None.\n",
    "\n",
    "Recall that we can use the DataFrame.isnull() method to identify missing values, which returns a boolean dataframe. We can then use the DataFrame.sum() method to give us a count of the True values for each column:\n",
    "```python\n",
    "print(laptops.isnull().sum())\n",
    "manufacturer            0\n",
    "model_name              0\n",
    "category                0\n",
    "screen_size_inches      0\n",
    "screen                  0\n",
    "cpu                     0\n",
    "ram_gb                  0\n",
    "storage                 0\n",
    "gpu                     0\n",
    "os                      0\n",
    "os_version            170\n",
    "weight_kg               0\n",
    "price_euros             0\n",
    "cpu_manufacturer        0\n",
    "screen_resolution       0\n",
    "cpu_speed               0\n",
    "dtype: int64\n",
    "It's now clear that we have only one column with null values, os_version, which has 170 missing values.\n",
    "```\n",
    "There are a few options for handling missing values:\n",
    "\n",
    "- Remove any rows that have missing values.\n",
    "- Remove any columns that have missing values.\n",
    "- Fill the missing values with some other value.\n",
    "- Leave the missing values as is.\n",
    "The first two options are often used to prepare data for machine learning algorithms, which are unable to be used with data that includes null values. We can use the DataFrame.dropna() method to remove or drop rows and columns with null values.\n",
    "\n",
    "The DataFrame.dropna() method accepts an axis parameter, which indicates whether we want to drop along the column or index axis. Let's look at an example:\n",
    "\n",
    "<img src=\"dropna_1.svg\" width=600 height=100>\n",
    "\n",
    "\n",
    "\n",
    "The default value for the axis parameter is 0, so df.dropna() returns an identical result to df.dropna(axis=0):\n",
    "\n",
    "<img src=\"dropna_2.svg\" width=600 height=100>\n",
    "\n",
    "The rows with labels x and z contain null values, so those rows are dropped. Let's look at what happens when we use axis=1 to specify the column axis:\n",
    "\n",
    "<img src=\"dropna_3.svg\" width=600 height=100>\n",
    "\n",
    "Only the column with label C contains null values, so, in this case, just one column is removed.\n",
    "\n",
    "Let's practice using DataFrame.dropna() to remove rows and columns:\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Use DataFrame.dropna() to remove any rows from the laptops dataframe that have null values. Assign the result to laptops_no_null_rows.\n",
    "- Use DataFrame.dropna() to remove any columns from the laptops dataframe that have null values. Assign the result to laptops_no_null_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops_no_null_rows = laptops.dropna()\n",
    "laptops_no_null_cols = laptops.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "- Use a boolean array to identify rows that have the value No OS for the os column. Then, use assignment to assign the value Version Unknown to the os_version column for those rows.\n",
    "- Use the syntax below to create value_counts_after variable:\n",
    "    value_counts_after = laptops.loc[laptops[\"os_version\"].isnull(), \"os\"].value_counts()\n",
    "\n",
    "- After running your code, use the variable inspector to look at the difference between value_counts_before and value_counts_after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown      66\n",
       "Linux        62\n",
       "Chrome OS    27\n",
       "Android       2\n",
       "Name: os, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts_before = laptops.loc[laptops[\"os_version\"].isnull(), \"os\"].value_counts()\n",
    "laptops.loc[laptops[\"os\"] == \"macOS\", \"os_version\"] = \"X\"\n",
    "laptops.loc[laptops.os == 'No OS', 'os'] = 'Unknown'\n",
    "value_counts_after = laptops.loc[laptops.os_version.isnull(),'os'].value_counts()\n",
    "value_counts_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it appears that the weight column may just need the kg characters removed from the end of each string, there is one special case - one of the values ends with kgs, so you'll have to remove both kg and kgs characters.\n",
    "\n",
    "In the last step of this challenge, we'll also ask you to use the DataFrame.to_csv() method to save the cleaned data to a CSV file. It's a good idea to save a CSV when you finish cleaning in case you wish to do analysis later.\n",
    "\n",
    "We can use the following syntax to save a CSV:\n",
    "```python\n",
    "df.to_csv('filename.csv', index=False)\n",
    "```\n",
    "By default, pandas will save the index labels as a column in the CSV file. Our data set has integer labels that don't contain any data, so we don't need to save the index.\n",
    "\n",
    "Don't be discouraged if this challenge takes a few attempts to get correct. Working iteratively is a great way to work, and this challenge is more difficult than exercises you have previously completed. We have included some extra hints, but we encourage you to try without the hints first; only use them if you need them!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Convert the values in the weight column to numeric values.\n",
    "- Rename the weight column to weight_kg.\n",
    "- Use the DataFrame.to_csv() method to save the laptops dataframe to a CSV file laptops_cleaned.csv without index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-b849372173be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlaptops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlaptops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'kgs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'kg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlaptops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'weight_kg'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlaptops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'laptops_cleaned.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5174\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5175\u001b[0m         ):\n\u001b[1;32m-> 5176\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5177\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0maccessor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36m_validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only use .str accessor with string \"\u001b[0m \u001b[1;34m\"values!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "laptops.weight = laptops.weight.str.replace('kgs','').str.replace('kg','').astype(float)\n",
    "laptops.rename({'weight':'weight_kg'})\n",
    "laptops.to_csv('laptops_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
